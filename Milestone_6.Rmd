---
title: 'Milestone #6'
author: "Cian Stryker"
date: "3/17/2020"
output: pdf_document
---

\fontsize{10}{18}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

# Loading all libraries
# that I'll need. 

library(foreign)
library(plyr)
library(AER)
library(data.table)
library(gt)
library(stargazer)
library(tidyverse)
```

```{r Loading}

# My loading code. 

load("~/Replication_Project/Data/kyrgyzstan.RData")
data <- table

```

I will be replicating the paper "Ethnic Riots and Prosocial Behavior: Evidence from Kyrgyzstan" written by Anselm Hager, Krzysztof Krakowski, and Max Schaub.[^1] Using survey data performed in Osh, Kyrgyzstan after the 2010 ethnic riots, this paper explores the question of whether exposure to ethnic riots has a negative effect on both in and out group member prosocial behavior. Previous literature on prosocial behavior following ethnic violence suggests, intuitively, that prosocial behavior towards the aggressor group is negatively affected.[^2] This paper's results, however, supports the work of other scholars who found that prosocial behavior for both in and out groups are negatively affected. [^3] 


[^1]: Hager, Krakowski, and Schaub 2019

[^2]: Bauer et al. 2016; Horowitz 2001

[^3]:Kijewski and Freitag 2018; Rohner, Thoenig, and Zilibotti 2013;



The first step to understanding the data analysis performed in the following replication, is to become familiar with the event itself. The 2010 ethnic riots happened in Osh, Kyrgyzstan and were comprised of the ethnic Kyrgyz majority rioting against the ethnic Uzbek minority.[^4] The second step is to understand the author's data. They performed 1100 interviews with Uzbeks and Kyrgyz from Osh, Kyrgyzstan. View the graphic I have created below to see how the interview subjects differentiate between ethnicities, average ages, average incomes, gender, and number affected by riots.[^5]

[^4]:Galdini 2014

[^5]: All analysis for this paper is available here: https://github.com/CianStryker/Project_5_Milestone


\hfill\break

```{r Summary Table, include=FALSE}

# I want to grab some Uzbek data
# and show the break down. SO I 
# essentially just keep filtering
# and summarizing my data into different
# groups. 

uzbek <- data %>%
  filter(ethnicity == "Uzbek") 
uzbek_total <- uzbek %>%
  summarize(Total = nrow(uzbek))
uzbek_age <- uzbek %>%
  summarize(Age = mean(age))
uzbek_income <- uzbek %>%
  summarize(Income = mean(income))

uzbek_men <- uzbek %>%
  filter(sex == 1) %>%
  summarize(male = sum(sex)) %>%
  summarize(Men = (male/878))

uzbek_women <- uzbek %>%
  filter(sex == 0) %>%
  mutate(sex2 = sex + 1) %>%
  summarize(female = sum(sex2)) %>%
  summarize(Women = (female/878))

uzbek_affected <- uzbek %>%
  filter(affected == 1) %>%
  summarize(Affected = sum(affected))

uzbek_non_affected <- uzbek %>%
  filter(affected == 0) %>%
  mutate(affected2 = affected + 1) %>%
  summarize(Unaffected = sum(affected2))

# Then I make one big Uzbek data frame. 

uzbeks <- data.frame(uzbek_total, uzbek_age, uzbek_income, uzbek_men, uzbek_women, uzbek_affected, uzbek_non_affected) 

# And then I melt into the right format. 

uzbeks2 <- reshape2::melt(uzbeks)


# Same steps as before but now for Kyrgyz
# instead of Uzbeks. 

kyrgyz <- data %>%
  filter(ethnicity == "Kyrgyz")

kyrgyz_total <- kyrgyz %>%
  summarize(Total = nrow(kyrgyz))

kyrgyz_age <- kyrgyz %>%
  summarize(Age = mean(age))

kyrgyz_income <- kyrgyz %>%
  summarize(Income = mean(income))

kyrgyz_men <- kyrgyz %>%
  filter(sex == 1) %>%
  summarize(male = sum(sex)) %>%
  summarize(Men = (male/222))

kyrgyz_women <- kyrgyz %>%
  filter(sex == 0) %>%
  mutate(sex2 = sex + 1) %>%
  summarize(female = sum(sex2)) %>%
  summarize(Women = (female/222))

kyrgyz_affected <- kyrgyz %>%
  filter(affected == 1) %>%
  summarize(Affected = sum(affected))

kyrgyz_non_affected <- kyrgyz %>%
  filter(affected == 0) %>%
  mutate(affected2 = affected + 1) %>%
  summarize(Unaffected = sum(affected2))

kyrgyzz <- data.frame(kyrgyz_total, kyrgyz_age, kyrgyz_income, kyrgyz_men, kyrgyz_women, kyrgyz_affected, kyrgyz_non_affected)

kyrgyz2 <- reshape2::melt(kyrgyzz)

# Only unqiue code here is to create better variable names
# for my gt table.

trial <- c("Total", "Average Age", "Average Income", "Percentage Men", "Percentage Women", "Number Affected", "Number Unaffected")

# Now I mage my final data frame with 
# both Uzbek and Kyrgyz data. 

table_data <- data.frame(trial, uzbeks2, kyrgyz2)

# And I use gt to make a great table with good
# labels and that formats my numbers how I 
# want them to be formatted. 

table_data2 <- data.frame(trial, table_data) %>%
  select(trial, value, value.1) %>%
  gt() %>%
  fmt_number(columns = vars("value", "value.1"),
             decimals = 0, use_seps = TRUE) %>%
  cols_label("trial" = " ", "value" = "Uzbeks",
             "value.1" = "Kyrgyz") %>%
  fmt_percent(
              columns = c("value", "value.1"),
              rows = c(4, 5),
              decimals = 0,
              drop_trailing_zeros = FALSE,
              use_seps = TRUE,
              pattern = "{x}",
              sep_mark = ",",
              dec_mark = ".",
              incl_space = FALSE,
              placement = "right",
              locale = NULL) %>%
  tab_header(
    title = "Table 1: Summary of Survey Data",
    subtitle = "Separated between Uzbeks and Kyrgyz"
  ) %>%
  cols_align(align = c("center"), columns = TRUE)

```

```{r Summary Table Output, fig.align="center"}

# Print the table. 

table_data2
```

\hfill\break

In the authors' analyses they measure prosocial behavior by having subjects complete a prisoner's dilemma (PD) scenario and dictator’s game (DG) hypothetical to measure prosocial behavior towards both the in-group and out-group. They also create a ‘Prosociality Index’ score, which is simply a combined score of the PD and DG scores. They use these responses, which are measured numerically, to first run a series of OLS linear regressions for only Uzbeks who were affected by the riots, which is referred to as the victimization variable. They find that on average Uzbeks who were affected by the riots have lower prosocial behavior for both in and out-group members. They then run another series of regressions for affected Uzbeks, but include potential confounding variables such as wealth, state capacity of neighborhoods, community policing, accessibility, and voting record in the recent Kyrgyz election. They found, however, that only exposure to violence during the riots had consistently statistically significant effects on prosocial behavior. 

The authors then want to explore an instrumental variable which was the rioter’s access to armored vehicles (APCs) to break through Uzbek barricades. During the riot, APCs were captured from the Kyrgyz military barracks by rioters to then attack Uzbek enclaves. Areas of Osh where rioters did not have access to APCs saw little to no destruction. This suggests that access to APCs might act as an exogenic assignment mechanism that explains post-riot differences across subject responses. They believe that distance to APC locations capture the ‘intent-to-treat’ effect and then create a closeness instrument by inputting subjects’ distance to APC locations. The authors run a series of new regressions where they substitute victimization for the closeness instrument and then include these regressions with their earlier, original regressions. They see both that their original results hold and that even with victimization replaced with the closeness instrument, there is still a noticeable negative effect on prosocial behavior. They follow this up with a randomization inference procedure, where they randomized potential APC locations, to see if the earlier closeness instrument effect could occur randomly. They find, however, that this is highly unlikely. 

Overall the paper essentially finds that being affected by the riot causes a drop in prosocial behavior towards both the in-group and out-group. They then test the robustness of these results through potential confounding variables and an instrument variable. They find that their original findings hold throughout these robustness tests. At the end of the paper they explore why in-group prosocial behavior is negatively affected qualitatively and argue that disappointment and suspicion may explain the negatively affected in-group prosocial behavior.  
\hfill\break


\begin{center}
 Replication Statement
\end{center}

The replicable and essential figures/tables for my paper are Figures 4, 5, 6, 8, and 9, as well as Table 1. Figures 1, 2, 3, and 7 are made either via GIS software or are simply maps of Osh. These I could just screen shot and insert into my own work if necessary. There is also an online Appendix that is huge but it mostly consists of extensive robustness testing and therefore I consider it non-essential for the paper overall. Figures 4, 5, 8, 9 and Table 1 are replicable and are shown in the Appendix of this milestone. I currently cannot replicate Figure 6 from my paper, because the matrix they created does not work with the code they have provided. I have no way to edit this matrix without damaging the paper's findings. I am working with Alice to find a workaround, but since my extensions are focused on Figure 5 and Table 1 this will not prevent me from moving forward with the project. I also want to replicate one appendix figure, A.17 for my extension section, but it relies on the same matrix data as Figure 6, so it is not replicable as of now.   

\hfill\break


\begin{center}
 Extension Plans
\end{center}

I believe there are a few areas that could be expanded upon in this paper that the authors did not fully explore. An issue I have is that this study is non-observational and was published only a few months ago in late 2019, which means that there is no option to either incorporate additional data or necessarily rely on new additional literature that would suggest a weakness in the authors’ methodological approach. Even so, however, there are two areas where I feel more exploration of the data is warranted or where fundamental assumptions can be challenged. These areas would be a more robust exploration of the Kyrgyz subset of the survey data and a more in-depth exploration of prosocial confounding variables for the Uzbek data. 

My immediate reaction to reading the paper was that the predominant amount of attention was paid to the Uzbek subset of the data. This is intuitive because the study is aimed at understanding victimization from ethnic riots and the ethnic riots in Osh, Kyrgyzstan revolved around the Kyrgyz ethnic majority attacking the Uzbek ethnic minority. The survey data includes 222 surveys of Kyrgyz citizens of Osh and within this amount over a third were negatively affected by the ethnic riots as well. Now obviously this amount is much less than the nearly half out of 878 Uzbeks citizens that were affected, but they form an interesting point of comparison for the study. The only comparative exploration of affected Kyrgyz prosocial behavior done by the authors was to measure their prosocial behavior via regressions using the instrumental variable. Now I am critical of this approach because their instrumental variable is non-replicable, and their instrumental variable was only a robustness test. Their key findings are from Figure 5 where they simply ran linear regressions to measure prosocial behavior of affected Uzbeks relying on the victimization variable. When they use the affected Kyrgyz to compare results, they use the instrumental variable and then compare these results to their main results, but they two are not necessarily the same. I will then rerun their Figure 5 testing but on the Kyrgyz subset of the data instead. I will also use this subset to recreate their Table 1, to see how Kyrgyz differed on the various scores and whether their prosocial behavior can be explained by confounding variables. 

I also find that the author’s exploration of confounding variables for the Uzbek subset of the data is limited in its scope. They combine a variety of variables together to create their hypothetical confounders that might explain riot location, but I believe other variables should be included that would explain over prosocial behavioral scores. Namely, the use of common language and ethnicity of employer should be tested. Using a common language is a prosocial behavior that individuals opt into and this may have a strong impact on overall prosocial behavior after the riots. Also, ethnicity of one’s employer is interesting because if one’s employer is of the opposite ethnic group, this would mandate interaction with the out-group, which might generate higher prosocial behavior as well. Exploring the effect these variables have on Uzbek prosocial behavior and potentially their interaction with the victimization variable might provide some interesting insights into confounders for prosocial behavior. 


\pagebreak



\begin{center}
 Bibliography
\end{center}


\begingroup
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}

Bauer, Michal, Christopher Blattman, Julie Chytilova, Joseph Henrich, Edward Miguel, and Tamar Mitts. 2016. “Can War Foster Cooperation.” The Journal of Economic Perspectives 30 (3): 249–74.

Galdini, Franco. 2014. “Kyrgyzstan Violence: Four Years On.” July 1, 2014.
https://www.aljazeera.com/indepth/opinion/2014/06/kyrgyzstan-violence-2010-201463016460195835.html.

Hager, Anselm, Krzysztof Krakowski, and Max Schaub. 2019. “Ethnic Riots and Prosocial Behavior: Evidence from Kyrgyzstan.” American Political Science Review 113 (4): 1029–44.

Horowitz, Donald L. 2001. The Deadly Ethnic Riot. Berkelely: University of California.

Kijewski, Sara, and Markus Freitag. 2018. “Civil War and the Formation of Social Trust in Kosovo: Posttraumatic Growth or War-Related Distress?” Journal of Conflict Resolution 62 (4): 717–42.

Rohner, Dominic, Mathias Thoenig, and Fabrizio Zilibotti. 2013. “Seeds of Distrust: Conflict in Uganda.” Journal of Economic Growth 18 (3): 217–52.



\endgroup


\pagebreak


\begin{center}
 Appendix
\end{center}

\hfill\break
\hfill\break
\hfill\break


\begin{center}
\textbf{Summary Table}
```{r Summary Table Appendix Output, fig.align="center"}

# Print the table. 

table_data2
```

\end{center}

\hfill\break
\hfill\break
\hfill\break
\hfill\break
\hfill\break


```{r, Figure 4}

# So I figured it would be easy to replicate
# thier Figure 4 even though they don't give
# any replicable code. I just make some
# columns and then use gt to make it look like
# thier table. 

f4_1 <- c("+", "-", "-", "+")
f4_2 <- c(60, 80, 20, 100)
f4_3 <- c(60, 80, 100, 20)
f4_4 <- c("-", "+", "-", "+")

f4 <- data.frame(f4_1, f4_2, f4_3, f4_4) %>%
  gt() %>%
  cols_label("f4_1" = " ", "f4_2" = " ", "f4_3" = " ", "f4_4" = " ") %>%
  tab_spanner(
    label = "You", 
    columns = vars(
      f4_1, f4_2)
    ) %>%
  tab_spanner(
    label = "Partner", 
    columns = vars(
      f4_3, f4_4
    )
  )
```

\begin{center}

\textbf{Figure 4. Payoff Illustration in Prisoner's Dilemma}

\end{center}

```{r Figure 4 Output, fig.align="center"}

# Printing

f4
```

\pagebreak

```{r Figure 5}

# Just shifting the data I  want to use later by making certain
# columns integers, specifically the affected 
# and prisoner dilemma columns. Oh and the affected
# - 1 bit is to shift the binary from 1 and 0s to
# 0 and -1s. 

data$affected <- as.integer(data$affected)
data$affected <- data$affected - 1
data$pd_in <- as.integer(data$pd_in)
data$pd_out <- as.integer(data$pd_out)


# Just want to grab the data for Uzbeks
# as opposed to including the data for Kyrgyz 
# respondents. 

data_uzbek <- data[which(data$ethnicity=="Uzbek"),]


data_uzbek$pd_in_scale <- scale(data_uzbek$pd_in)
data_uzbek$dg_in_scale <- scale(data_uzbek$dg_in)
data_uzbek$pd_out_scale <- scale(data_uzbek$pd_out)
data_uzbek$dg_out_scale <- scale(data_uzbek$dg_out)
data_uzbek$cooperation_index <- rowSums(cbind(data_uzbek$pd_in_scale, 
                                              data_uzbek$dg_in_scale, 
                                              data_uzbek$pd_out_scale, 
                                              data_uzbek$dg_out_scale), na.rm=T)/4


# Alright I totally understand what's happening here. 
# They are just running an OLS regression on the variables
# that they made and scaled in the last step and trying
# to see the effect that the affected variable had on each
# of them in turn. 

model1 <- lm(pd_in_scale ~ affected, data=data_uzbek)
model2 <- lm(dg_in_scale ~ affected, data=data_uzbek)
model3 <- lm(pd_out_scale ~ affected, data=data_uzbek)
model4 <- lm(dg_out_scale ~ affected, data=data_uzbek)
model5 <- lm(cooperation_index ~ affected, data=data_uzbek)


# This all makes sense too. After running the regressions 
# the authors have 5 list type data, but they need to extract 
# the information that they want. It's kinda weird but I see that 
# using this code they are getting the Variable, Coefficient, 
# standard error, and name of test for each model. Cool. 

model1Frame <- data.frame(Variable = rownames(summary(model1)$coef),
                          Coefficient = summary(model1)$coef[, 1],
                          SE = summary(model1)$coef[, 2],
                          modelName = "Prisoner's Dilemma ingroup")[2,]
model2Frame <- data.frame(Variable = rownames(summary(model2)$coef),
                          Coefficient = summary(model2)$coef[, 1],
                          SE = summary(model2)$coef[, 2],
                          modelName = "Dictator Game ingroup")[2,]
model3Frame <- data.frame(Variable = rownames(summary(model3)$coef),
                          Coefficient = summary(model3)$coef[, 1],
                          SE = summary(model3)$coef[, 2],
                          modelName = "Prisoner's Dilemma outgroup")[2,]
model4Frame <- data.frame(Variable = rownames(summary(model4)$coef),
                          Coefficient = summary(model4)$coef[, 1],
                          SE = summary(model4)$coef[, 2],
                          modelName = "Dictator Game outgroup")[2,]
model5Frame <- data.frame(Variable = rownames(summary(model5)$coef),
                          Coefficient = summary(model5)$coef[, 1],
                          SE = summary(model5)$coef[, 2],
                          modelName = "Index")[2,]

# So now they want to put all those extracted models together
# in one dataframe. Cool. Checks out. They're using rbind to do taht
# giving them a numeric order, and then using factor to put them 
# in the order that they want. Not really sure what levels() does, 
# but it looks like it cleans up the variable names to make them 
# easier to graph later. 


allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame, model4Frame, model5Frame))
allModelFrame$Variable <- c(1,2,3,4, 5)
allModelFrame$Variable <- factor(allModelFrame$Variable, 
                                 labels=c("Prisoner's Dilemma  Ingroup", "Dictator Game  Ingroup", 
                                          "Prisoner's Dilemma  Outgroup", "Dictator Game  Outgroup", 
                                          "Prosociality  Index"))
levels(allModelFrame$Variable) <- gsub("  ", "\n", levels(allModelFrame$Variable))

# Okay so they want to set confidence intervals 
# at 90% and 95%. Seems clear. 

interval1 <- -qnorm((1-0.90)/2)  # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier

# They want all colors to be 00000, which is probably black right? 

myColors <- c("#000000", "#000000", "#000000", "#000000", "#000000")

# I understand ggplot so this is cool. A bunch of detail stuff such
# as adding a vertical dotted line at 0.00 mark. Then they make a 
# horizontal linerange for every variable with thier ranges being
# the SE * the confidence intervals calculated before. Then the points
# show the mean effect which is the SE times the 95% CI with some cool
# shapes added in for coolness. Switching up the y axis labels, setting
# the theme, setting the colors, getting rid of the ticks, and generally
# making things pretty. 

figure5 <- ggplot(allModelFrame, aes(colour = as.factor(Variable))) + 
  geom_hline(yintercept = 0, colour = gray(1/2), lty = 2) + 
  geom_linerange(aes(x = Variable, 
                     ymin = Coefficient - SE*interval1,
                     ymax = Coefficient + SE*interval1),
                     lwd = 1, position = position_dodge(width = 1/2)) + 
  geom_pointrange(aes(x = Variable, y = Coefficient, 
                      ymin = Coefficient - SE*interval2,
                      ymax = Coefficient + SE*interval2),
                      lwd = 1/4, position = position_dodge(width = 1/2),
                      shape = 21, fill = "WHITE") + 
  coord_flip(ylim = c(-0.8,0.2)) + 
  scale_y_continuous(labels = c("-0.75", "-0.50", "-0.25", "0.00", "0.2")) +
  theme_bw() + 
  theme(legend.position="none") + 
  ylab("")  + xlab("") +     
  scale_color_manual(values=myColors) +   
  theme(text = element_text(size=11), 
        plot.title = element_text(size = 10, face = "bold"), 
        plot.subtitle = element_text(size = 11, face = "italic")) +
  theme(plot.title = element_text(hjust = 0.5))

```


\begin{center}
\textbf{Figure 5. Effect of Riot on Prosocial Behavior}

```{r Figure 5 Output, fig.align="center"}

# Printing the figure.

figure5
```

\end{center}

\pagebreak


\begin{center}
\textbf{Figure 6.  Effect of Riot Destruction on Prosocial Behavior (IV)}

This Figure is currently non-replicable. See replication section for details. 

\end{center}

\pagebreak

```{r Figure 8, cache=TRUE, include=FALSE}

# Like I said before the scaling code doesn't change
# in between the figures so I won't comment on it 
# much anymore. This is just thier scaling and making
# the cooperation index var.

data_uzbek <- data[which(data$ethnicity=="Uzbek"),]
data_uzbek$pd_in_scale <- scale(data_uzbek$pd_in)
data_uzbek$dg_in_scale <- scale(data_uzbek$dg_in)
data_uzbek$pd_out_scale <- scale(data_uzbek$pd_out)
data_uzbek$dg_out_scale <- scale(data_uzbek$dg_out)
data_uzbek$cooperation_index <- rowSums(cbind(data_uzbek$pd_in_scale, data_uzbek$dg_in_scale, data_uzbek$pd_out_scale, data_uzbek$dg_out_scale), na.rm=T)/4
data_uzbek$distance <- data_uzbek$apc_min_distance


# So the first lin eis a typical regression. The third
# is also a typical regression but for the instrument i.e.
# distance to apc vehicle. The second is an instrumental 
# variable regression. I understand what it is by reading
# the notes on it, but I'll need more time to get
# what it is doing here. 

ols <- lm(cooperation_index ~ affected, data = data_uzbek)
iv <- ivreg(cooperation_index ~ affected | distance , data = data_uzbek)
instrument <- lm(cooperation_index ~ distance , data = data_uzbek)

# So here the authors wanted to randomize APC locations to 
# test the affect they have on figure 6. I get that. So they load in 
# the distance data they chose for that. Their note says 
# "Insheet distances from any given PSU to 9500 randomly chosen APC locations"

DistMat <- as.data.frame(read.csv("Data/distances_ri.csv", header = TRUE, sep =","))[-1]

# So every column in DistMat has an X in it. Here they really just want
# to get rid of those. 

colnames(DistMat) <- c(na.omit(as.numeric(unlist(strsplit(as.matrix(colnames(DistMat)), "X"))))) 

# Now they want to obtain PSU names from 
# the survey data as character to match to DistMat

psus <- c(as.character(unique(data_uzbek$id_psu)))

# Here they want to reduce distance matrix to 
# entries for PSUs where they sampled Uzbek respondents

sample_psus <- names(DistMat)[(names(DistMat) %in% psus)]
DistMat <- DistMat[, sample_psus]

# So the authors also had data about whether these apc locations
# were east of the Akbuura river or not. This is them loading it in 
# and then adding it to their other data. 

eoa <- as.data.frame(read.csv("Data/ri_east_of_akbuura.csv", header = TRUE))[2]
DistMat$eoa <-eoa

# Now they want to create matrices of whether the locations were
# east or west of the Akbuura river. Then they wanted to 
# make them into separate dataframes. 

DistMat_east <- subset(DistMat, eoa==1)
DistMat_west <- subset(DistMat, eoa==0)
DistMat = subset(DistMat, select = -c(eoa) )
DistMat_west = subset(DistMat_west, select = -c(eoa) )
DistMat_east = subset(DistMat_east, select = -c(eoa) )

# Setting the seed for some randomization but also
# they wanted to fill up the vectors so that they both have legnths of 
# 5000 apparently. 

set.seed(1000)
DistMat_east <- rbind(DistMat_east, DistMat_east[sample(169), ])
set.seed(1000)
DistMat_west <- rbind(DistMat_west, DistMat_west[sample(331),])

# I get this step now. They want to shuffle thier
# data sets from before. 

set.seed(1000)
DistMat_east <- DistMat_east[sample(nrow(DistMat_east)),]
set.seed(1000)
DistMat_west <- DistMat_west[sample(nrow(DistMat_west)),]

# They are creating a randome samling with replacment data frame. 

n <- 10000
set.seed(1000)
rand_vals <- sample(c(1:5000), n, replace = TRUE)

# They want to "store coefficient in vector
# with elements equal to draws" according to thier
# code comments. I follow that. 

estim <- matrix(0, nrow=n, ncol=1)

# Okay so this is tricky right, but they are using foor
# loop to loop through all values. 

j <- 0
for (i in rand_vals){
  j <- j + 1
  
   
# Then they are taking a distance from both east and west, transposing,
# finding minimum distance and then adding a column for matching. 
  
  dist_i_west <- as.data.frame(t(DistMat_west[i,]))
  dist_i_east <- as.data.frame(t(DistMat_east[i,]))
  dist_i <- cbind(dist_i_west, dist_i_east)

# Then they choose the APC location in east or west that is closest to thier
# interview location, according to thier notes. 
  
  dist_i <- as.data.frame(apply(dist_i, 1, FUN=min))
  dist_i <- setDT(dist_i, keep.rownames = TRUE)
  colnames(dist_i)=c("id_psu", "drivedist")
  
# Then they merge the data. 
  
  combinedData <- join(data_uzbek, dist_i, by='id_psu', type='left', match='all')
  
# Then they run a regression on the coperation index and 
# the new locations. 
  
  ivest_i <- lm(cooperation_index ~ drivedist, data=combinedData)  
  
# Then they save the results somehow and merge them 
# to the coef matrix they made earlier. 
  
  estim[j,1] <- estim[j,1] + coef(ivest_i)[2] 
}

# Okay I'm back to understanding things. So here they are shifting their
# dat to negative again. Making it a data frame and finding the mean. 

estim <- estim*-1  #convert to negative scale "closeness to barracks"
data_combined <- as.data.frame(estim)
mean(estim)

# Graphing code is graphic code. They make a density plot. 
# Then they add in a bunch of details like a vertical line
# and such. 

figure8 <- ggplot(data_combined, aes(x=V1)) +  
  geom_density(bw = 0.02) +
  theme_bw() + 
  ylab("Density")  + xlab("Estimate") +     
  theme(text = element_text(size=11)) +
  scale_x_continuous(limits = c(-0.2,0.2)) + 
  geom_vline(xintercept=instrument$coefficients[2]*-1, linetype=2, color = "grey") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))

```


\begin{center}
\textbf{Figure 8. Randomization Inference}

```{r Figure 8 Output, fig.align="center"}

# Time to make the actual graph. 

figure8
```

\end{center}

\pagebreak


```{r Figure 9}

# They're just making affected an 
# integer again and then shifting the
# binary state to negative 1 and 0.

data$affected <- as.integer(data$affected)
data$affected <- data$affected - 1

# Now they subset the data. 

data_uzbek <- data[which(data$ethnicity=="Uzbek"),]

# This bit of the paper is an exploration of whether
# the people who were affected by the riots actually
# had more damages than other types. So they run the 
# OLS regressions on each type of loss. 

model1 <- lm(losses_1 ~ affected, data=data_uzbek)
model2 <- lm(losses_2 ~ affected, data=data_uzbek)
model3 <- lm(losses_3 ~ affected, data=data_uzbek)
model4 <- lm(losses_4 ~ affected, data=data_uzbek)
model5 <- lm(losses_5 ~ affected, data=data_uzbek)


# Here they just want to grab their coefficients from 
# the regressions they ran earlier. 

model1Frame <- data.frame(Variable = rownames(summary(model1)$coef),
                          Coefficient = summary(model1)$coef[, 1],
                          SE = summary(model1)$coef[, 2],
                          modelName = "Car")[2,]
model2Frame <- data.frame(Variable = rownames(summary(model2)$coef),
                          Coefficient = summary(model2)$coef[, 1],
                          SE = summary(model2)$coef[, 2],
                          modelName = "TV")[2,]
model3Frame <- data.frame(Variable = rownames(summary(model3)$coef),
                          Coefficient = summary(model3)$coef[, 1],
                          SE = summary(model3)$coef[, 2],
                          modelName = "House")[2,]
model4Frame <- data.frame(Variable = rownames(summary(model4)$coef),
                          Coefficient = summary(model4)$coef[, 1],
                          SE = summary(model4)$coef[, 2],
                          modelName = "Money")[2,]
model5Frame <- data.frame(Variable = rownames(summary(model5)$coef),
                          Coefficient = summary(model5)$coef[, 1],
                          SE = summary(model5)$coef[, 2],
                          modelName = "Business")[2,]

# Here they once again want to combine all thier data into one. 
# They also want to list them in a particular order. 

allModelFrame <- data.frame(rbind(model1Frame, model2Frame, model3Frame, model4Frame, model5Frame))
allModelFrame$Variable <- c(1,2,3,4, 5)
allModelFrame$Variable <- factor(allModelFrame$Variable, labels=c("Car", "TV", "House", "Money", "Business"))
levels(allModelFrame$Variable) <- gsub("  ", "\n", levels(allModelFrame$Variable))

# Now they want to calculat the 90 and 95 CIs. 

interval1 <- -qnorm((1-0.90)/2)  # 90% multiplier
interval2 <- -qnorm((1-0.95)/2)  # 95% multiplier

# And then its another round of color setting. 

myColors <- c("#000000", "#000000", "#000000", "#000000", "#000000")


# Same graphing code from Figure 5 and 6. Refer to my comments
# on Figure 5 for a more detailed analysis of what's happening. 

figure9 <- ggplot(allModelFrame, aes(colour = as.factor(Variable))) + 
  geom_hline(yintercept = 0, colour = gray(1/2), lty = 2) + 
  geom_linerange(aes(x = Variable, ymin = Coefficient - SE*interval1,
                     ymax = Coefficient + SE*interval1),
                 lwd = 1, position = position_dodge(width = 1/2)) + 
  geom_pointrange(aes(x = Variable, y = Coefficient, ymin = Coefficient - SE*interval2,
                      ymax = Coefficient + SE*interval2),
                  lwd = 1/4, position = position_dodge(width = 1/2),
                  shape = 21, fill = "WHITE") + 
  coord_flip(ylim = c(-0.1,0.3)) + theme_bw() + 
  theme(legend.position="none") + 
  #ggtitle("Cooperation among Uzbeks") +  
  ylab("")  + xlab("") +     
  scale_color_manual(values=myColors) +   
  theme(text = element_text(size=11)) +
  theme(plot.title = element_text(hjust = 0.5))
```

\begin{center}
\textbf{Figure 9. Effect of Riot Destruction on Losses}

```{r Figure 9 Output, fig.align='center'}

# output

figure9
```

\end{center}

\pagebreak


```{r Table 1, include=FALSE}

# Same cleaning code that they've done
# for all figures. Its just as.integer commands
# and shifting the binary.

data$affected <- as.integer(data$affected)
data$affected <- data$affected - 1
data$pd_in <- as.integer(data$pd_in)
data$pd_out <- as.integer(data$pd_out)


# They wanted to rename a variable here. 

data$social_cap_retro <- data$leadership

# Subsetting time as per usual.

data_uzbek <- data[which(data$ethnicity=="Uzbek"),]

# And once more they wanted to scale everything. 
# Remind me to ask Alice to clarify what this does 
# in simple terms. I think I get it but I want to 
# make sure. 

data_uzbek$pd_in_scale <- scale(data_uzbek$pd_in)
data_uzbek$dg_in_scale <- scale(data_uzbek$dg_in)
data_uzbek$pd_out_scale <- scale(data_uzbek$pd_out)
data_uzbek$dg_out_scale <- scale(data_uzbek$dg_out)
data_uzbek$cooperation_index <- rowSums(cbind(data_uzbek$pd_in_scale, 
                                              data_uzbek$dg_in_scale, 
                                              data_uzbek$pd_out_scale, 
                                              data_uzbek$dg_out_scale), na.rm=T)/4

# So many multivariate linear regressions. So this 
# is their table info which requires the prisoner dilemma, 
# dictator game, and cooperation index to be regressed by 
# a bushel of variables. Here is where I'd like to do some
# playing around when its my turn to make changes. 

model1 <- lm(pd_in_scale ~ affected + economy_index + state_index + social_cap_retro + access_index + aj_vote_share, data=data_uzbek)
model2 <- lm(dg_in_scale ~ affected + economy_index + state_index + social_cap_retro + access_index + aj_vote_share, data=data_uzbek)
model3 <- lm(pd_out_scale ~ affected + economy_index + state_index + social_cap_retro + access_index + aj_vote_share, data=data_uzbek)
model4 <- lm(dg_out_scale ~ affected + economy_index + state_index + social_cap_retro + access_index + aj_vote_share, data=data_uzbek)
model5 <- lm(cooperation_index ~ affected + economy_index + state_index + social_cap_retro + access_index + aj_vote_share, data=data_uzbek)

# I actually don't know why they are
# running a summary on every model but
# I assume they need to in order to run
# the stargazer. 

summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
```

\begin{center}
\textbf{Table 1}
\end{center}

```{r Table 1 Stargazer, results = "asis"}

# Alright so this is weird. I know they are using stargazer 
# to make the really nice looking table in the paper. I don't know
# how this code works though. I can't seem to replicate it myself.
# This is something else I'll need Alice's help with. Or I just need 
# enough time to figure out how stargazer works. 

cat("\\scalebox{.55}{")

stargazer(model1, model2, model3, model4, model5,
          covariate.labels = c("Destruction", "Wealth index", "State capacity index", "Community policing index", "Accessibility index", "AJ %"),
          dep.var.labels = c("Cooperation in Prisoner's Dilemma", "Investment in Dictator Game", "Cooperation in Prisoner's Dilemma", "Investment in Dictator Game" , "Cooperation-Index"),
          star.char = c("*", "**", "***"),
          title = "Table 1: Effect of Destruction on Prosocial Behavior (controlling for confounders and mobilization)",
          star.cutoffs = c(0.05, 0.01, 0.001), type = 'latex', float = FALSE)


cat("}") 
```

\pagebreak


\begin{center}
\textbf{Figure A.17}

Figure A.17 is currently non-replicable. See replication section for details.


\end{center}

